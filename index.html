<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
    <title>Xin Wang - Fudan University</title>
    <meta name="description" content="Artificial General Intelligence">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="https://fonts.googleapis.com/css?family=Alegreya" rel="stylesheet">
    <!--<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400|Oswald:400,700' rel='stylesheet' type='text/css'>-->
    <link href="style.css" rel=stylesheet>
    <script>
        function showbib(tag) {
            var x = document.getElementById(tag);
            if (x.style.display == "block")
                x.style.display = "none";
            else x.style.display = "block";
        }
    </script>
</head>

<body>
    <div id=main>

    <!-- <div style="padding-top: 10px">
        <div style="float:right">
            <a class=link href="">Home</a>
                    &nbsp;&nbsp;&nbsp;
                    <a class=link href="">Publications</a>
                    <br><br>
        </div>
    </div> -->

        <div style="padding-top: 10px">

            <div style="float:left">
                <div class=name>Zejia Weng</div>
                <p> Ph.D. Candidate<br>School of Computer Science, Fudan University
                <p><a class=link href="mailto:xinwang22@m.fudan.edu.cn">Email</a>
                    <!--<a class="cv" href="resume-angli.pdf">Resume</a> -->&nbsp;&nbsp;&nbsp;
                    <a class=link href="https://scholar.google.com/citations?user=-3rl91gAAAAJ&hl=en">Google Scholar</a>
                    <br><br>
            </div>
            <div style="clear:both;"></div>
        </div>
        <div class=section>
            <h3>Biography</h3>
            <p>
            Hi, I'm <a href="https://scholar.google.com/citations?user=-3rl91gAAAAJ&hl=en">Xin Wang</a>, a Ph.D. student of <a href="https://fvl.fudan.edu.cn/">FVL Lab</a> in the School of Computer Science at Fudan University, advised by <a href="http://xingjunma.com/">Prof. Xingjun Ma</a> and <a href="https://scholar.google.com/citations?user=f3_FP8AAAAAJ&hl=en">Prof. Yu-Gang Jiang</a>.
            </p>
            <p>
            Recently, I am broadly interested in safety and alignment aspects of machine learning with a recent focus on large language models. Most of my past works are in the domain of trustworthy machine learning, particularly adversarial examples and robustness of machine learning algorithms.
            </p>
            <p>
            Feel free to reach me at xinwang22 <strong>[at]</strong> m <strong>[dot]</strong> fudan <strong>[dot]</strong> edu <strong>[dot]</strong> cn, if you are interested in potential collaborations</a>.
            </p>

            <div class="section">
                <h3>Publication</h3>
                <ul class="paper">
                  <li><b>TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models.</b><br>
                      CVPR, 2025<br>
                      <span class="authors"><b>Xin Wang</b>, K. Chen, J. Zhang, <i>et al.</i></span>
                  </li>
              
                  <li><b>AdvQDet: Detecting Query-Based Adversarial Attacks with Adversarial Contrastive Prompt Tuning.</b><br>
                      ACM MM, 2024<br>
                      <span class="authors"><b>Xin Wang</b>, K. Chen, X. Ma, <i>et al.</i></span>
                  </li>
              
                  <li><b>FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models.</b><br>
                      arXiv, 2025<br>
                      <span class="authors"><b>Xin Wang</b>, J. Li, Z. Weng, <i>et al.</i></span>
                  </li>
              
                  <li><b>SafeWork-R1: Coevolving Safety and Intelligence under the AI-45&deg; Law.</b><br>
                      Technical Report, 2025<br>
                      <span class="authors"><b>Shanghai AI Lab</b> (Core Contributor)</span>
                  </li>
              
                  <li><b>Adversarial Prompt Tuning for Vision-Language Models.</b><br>
                      ECCV, 2024<br>
                      <span class="authors">J. Zhang, X. Ma, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>SafeVid: Toward Safety-Aligned Video Large Multimodal Models.</b><br>
                      NeurIPS 2025 D&amp;B Track<br>
                      <span class="authors">Y. Wang, J. Song, Y. Gao, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>Safety at Scale: A Comprehensive Survey of Large Model Safety.</b><br>
                      FnTs&reg; in Privacy and Security, 2025<br>
                      <span class="authors">X. Ma, Y. Gao, Y. Wang, R. Wang, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>Argus Inspection: Do Multimodal Large Language Models Possess the Eye of Panoptes?</b><br>
                      ACM MM 2025 (Datasets Track)<br>
                      <span class="authors">Y. Yao, L. Li, J. Song, C. Chen, Z. He, Y. Wang, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>Lossless Medical Image Compression Based on Anatomical Information and Deep Neural Networks.</b><br>
                      Biomedical Signal Processing and Control, 2022<br>
                      <span class="authors">Q. Min, <b>Xin Wang</b>, B. Huang, <i>et al.</i></span>
                  </li>
              
                  <li><b>Web-Based Technology for Remote Viewing of Radiological Images: App Validation.</b><br>
                      Journal of Medical Internet Research, 2020<br>
                      <span class="authors">Q. Min* , <b>Xin Wang*</b>, B. Huang, <i>et al.</i></span>
                  </li>
              
                  <li><b>Evolve the Method, Not the Prompts: Evolutionary Synthesis of Jailbreak Attacks on LLMs.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">Y. Chen*, <b>Xin Wang*</b>, J. Li, <i>et al.</i></span>
                  </li>
              
                  <li><b>Simulated Ensemble Attack: Transferable Jailbreaks Across Fine-tuned Vision-Language Models.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">R. Wang, <b>Xin Wang</b>, Y. Yao, <i>et al.</i></span>
                  </li>
              
                  <li><b>NAP-Tuning: Neural Augmented Prompt Tuning for Adversarially Robust Vision-Language Models.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">J. Zhang, <b>Xin Wang</b>, X. Ma, <i>et al.</i></span>
                  </li>
              
                  <li><b>SafeEvalAgent: Toward Agentic and Self-Evolving Safety Evaluation of LLMs.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">Y. Wang, <b>Xin Wang</b>, X. Ma, <i>et al.</i></span>
                  </li>
              
                  <li><b>DarkLLaVA: Scalable Adversarial Attack with Large Language Models.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">Y. Sun, <b>Xin Wang</b>, J. Zhang, <i>et al.</i></span>
                  </li>
              
                  <li><b>Adversarial Prompt Distillation for Vision-Language Models.</b><br>
                      arXiv, 2024<br>
                      <span class="authors">L. Luo, <b>Xin Wang</b>, B. Zi, <i>et al.</i></span>
                  </li>
              
                  <li><b>A<sup>2</sup>RM: Adversarial-Augmented Reward Model.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">S. Huang, J. Li, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>LeakyCLIP: Extracting Training Data from CLIP.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">Y. Chen, S. Wang, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>Imperceptible Jailbreaking against Large Language Models.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">K. Gao, Y. Li, C. Du, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>DAVID-XR1: Detecting AI-Generated Videos with Explainable Reasoning.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">Y. Gao, Y. Ding, H. Su, J. Li, Y. Zhao, L. Luo, Z. Chen, L. Wang, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
              
                  <li><b>Trustworthy Embodied AI: A Comprehensive Survey.</b><br>
                      arXiv, 2025<br>
                      <span class="authors">X. Li, X. Zheng, Y. Gao, X. Xia, Y. Wang, R. Wang, <b>Xin Wang</b>, <i>et al.</i></span>
                  </li>
                </ul>
              </div>


            <div class=section>
                <h3>Hornors & Awards</h3>
                <ul class=misc>

                    <li class=misc0> First Class Award Scholarship of Fudan University, 2025
                    </li>
				   	<li class=misc0> Outstanding Student of Fudan University, 2023
                    </li>
				   	<li class=misc0> iDash Privacy \& Security Challenge Track 3: Confidential Computing, <b><u>Ranked 1st</u></b>, 2021
                    </li>
				   	<li class=misc0> Outstanding Graduate Award of Central China Normal University, 2020
                    </li>
				   	<li class=misc0> Outstanding Master's Thesis Award of Central China Normal University, 2021
                    </li>
                   
                </ul>
            </div>



            <div class=section>
                <h3>Professional Service</h3>
                <ul class=misc>

                    <li class=misc0> Conference Reviewer for ICLR, NeurIPS, ICCV, EMNLP, ACM MM, et al.
                    </li>
                    <li class=misc0> Journal Reviewer for IJCV, TIP, TCSVT, TNNLS, et al.
                    </li>
                   
                </ul>
            </div>

            <div class=foot style="font-size:10px"></div>
        </div>
</body>



</html>
